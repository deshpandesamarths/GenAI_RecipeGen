{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_1\n",
    "import pandas as pd\n",
    "import ast  # to safely parse list-like strings\n",
    "\n",
    "# Load CSV (replace path if needed)\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/FoodRecipeGenerator/RecipeNLG/RecipeNLG_dataset.csv\")\n",
    "\n",
    "# Convert stringified lists to actual lists\n",
    "df[\"ingredients\"] = df[\"ingredients\"].apply(ast.literal_eval)\n",
    "df[\"directions\"] = df[\"directions\"].apply(ast.literal_eval)\n",
    "\n",
    "# Combine into simplified format\n",
    "recipes = []\n",
    "for _, row in df.iterrows():\n",
    "    recipes.append({\n",
    "        \"title\": row[\"title\"],\n",
    "        \"ingredients\": row[\"ingredients\"],\n",
    "        \"instructions\": \" \".join(row[\"directions\"])  # combine steps\n",
    "    })\n",
    "\n",
    "# Optional: preview a recipe\n",
    "print(recipes[0])\n",
    "import pickle\n",
    "\n",
    "with open(\"/content/drive/MyDrive/FoodRecipeGenerator/recipes_cleaned.pkl\", \"wb\") as f:\n",
    "    pickle.dump(recipes, f)\n",
    "\n",
    "print(\"‚úÖ Recipes saved as Pickle!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_3\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Define save directory again\n",
    "save_dir = \"/content/drive/MyDrive/FoodRecipeGenerator/embeddings_batches\"\n",
    "\n",
    "# Load all batches\n",
    "all_embeddings = []\n",
    "for file in sorted(glob.glob(f\"{save_dir}/embeddings_batch_*.npy\")):\n",
    "    all_embeddings.append(np.load(file))\n",
    "\n",
    "# Combine into one big array\n",
    "embeddings = np.vstack(all_embeddings)\n",
    "\n",
    "print(\"Total embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize model with GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "# Settings\n",
    "batch_size = 1000\n",
    "save_dir = \"/content/drive/MyDrive/FoodRecipeGenerator/embeddings_batches\"\n",
    "\n",
    "# Create the directory if not exists\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"/content/drive/MyDrive/FoodRecipeGenerator/recipes_cleaned.pkl\", \"rb\") as f:\n",
    "    recipes = pickle.load(f)\n",
    "\n",
    "# Process in batches\n",
    "for i in range(0, len(recipes), batch_size):\n",
    "    batch_recipes = recipes[i:i+batch_size]\n",
    "    texts = [\" \".join(r[\"ingredients\"]) for r in batch_recipes]\n",
    "\n",
    "    print(f\"Encoding batch {i//batch_size + 1} ...\")\n",
    "    batch_embeddings = model.encode(\n",
    "        texts,\n",
    "        batch_size=64,\n",
    "        convert_to_numpy=True,\n",
    "        show_progress_bar=True\n",
    "    )\n",
    "\n",
    "    # Save the embeddings batch\n",
    "    batch_path = os.path.join(save_dir, f\"embeddings_batch_{i//batch_size + 1}.npy\")\n",
    "    np.save(batch_path, batch_embeddings)\n",
    "    print(f\"Saved: {batch_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio faiss-cpu sentence-transformers transformers accelerate sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_4 NO NEED TO RE RUN THIS CELL ALREADY SAVED\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load combined embeddings\n",
    "save_dir = \"/content/drive/MyDrive/FoodRecipeGenerator/embeddings_batches\"\n",
    "all_embeddings = []\n",
    "import glob\n",
    "for file in sorted(glob.glob(f\"{save_dir}/embeddings_batch_*.npy\")):\n",
    "    all_embeddings.append(np.load(file))\n",
    "embeddings = np.vstack(all_embeddings)\n",
    "\n",
    "# Convert to float32 (FAISS requires it)\n",
    "embeddings = embeddings.astype('float32')\n",
    "\n",
    "# Build the index\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # L2 distance\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the index\n",
    "faiss.write_index(index, \"/content/drive/MyDrive/FoodRecipeGenerator/recipe_faiss.index\")\n",
    "print(\"‚úÖ FAISS index saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import re\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"/content/drive/MyDrive/FoodRecipeGenerator/recipe_faiss.index\")\n",
    "\n",
    "# Load cleaned recipes\n",
    "with open(\"/content/drive/MyDrive/FoodRecipeGenerator/recipes_cleaned.pkl\", \"rb\") as f:\n",
    "    recipes = pickle.load(f)\n",
    "\n",
    "# Embedding model\n",
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')\n",
    "\n",
    "# Load Phi-2 model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\")\n",
    "phi_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/phi-2\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Search similar recipes\n",
    "def search_similar_recipes(query_ingredients, model, index, recipes, top_k=3):\n",
    "    query_text = \" \".join(query_ingredients)\n",
    "    query_embedding = model.encode(query_text, convert_to_numpy=True).astype('float32')\n",
    "    D, I = index.search(np.array([query_embedding]), k=top_k * 3)\n",
    "    results = []\n",
    "    used_indices = set()\n",
    "    for idx in I[0]:\n",
    "        if idx in used_indices:\n",
    "            continue\n",
    "        recipe_ingredients = [ing.lower() for ing in recipes[idx][\"ingredients\"]]\n",
    "        if any(q_ing.lower() in recipe_ingredients for q_ing in query_ingredients):\n",
    "            results.append(recipes[idx])\n",
    "            used_indices.add(idx)\n",
    "        if len(results) >= top_k:\n",
    "            break\n",
    "    if len(results) < top_k:\n",
    "        for idx in I[0]:\n",
    "            if idx not in used_indices:\n",
    "                results.append(recipes[idx])\n",
    "                used_indices.add(idx)\n",
    "            if len(results) >= top_k:\n",
    "                break\n",
    "    return results\n",
    "\n",
    "# Prompt builder\n",
    "def build_generation_prompt(input_ingredients, retrieved_recipes, num_examples=3):\n",
    "    prompt = \"You are a creative chef. Below are some example recipes:\\n\\n\"\n",
    "    for i, recipe in enumerate(retrieved_recipes[:num_examples]):\n",
    "        prompt += f\"üçΩ Recipe {i+1}: {recipe['title']}\\n\"\n",
    "        prompt += f\"Ingredients:\\n{', '.join(recipe['ingredients'])}\\n\"\n",
    "        prompt += f\"Instructions:\\n{recipe['instructions']}\\n\\n\"\n",
    "    prompt += f\"Now create a new, unique recipe using these ingredients:\\n\"\n",
    "    prompt += f\"{', '.join(input_ingredients)}\\n\"\n",
    "    prompt += \"Please format the instructions as clearly numbered steps (e.g., 1. ..., 2. ..., etc).\\n\"\n",
    "    prompt += \"\\nüçΩ Recipe Name:\"\n",
    "    return prompt\n",
    "\n",
    "# ‚úÖ FIXED: Extract final generated recipe correctly\n",
    "def extract_new_recipe_details(text):\n",
    "    recipe_pattern = re.compile(\n",
    "        r\"üçΩ Recipe Name:\\s*(.+?)\\n+Ingredients:\\s*(.+?)\\n+Instructions:\\s*(.+?)(?=(\\n+üçΩ Recipe Name:|\\Z))\",\n",
    "        re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    matches = recipe_pattern.findall(text)\n",
    "    if not matches:\n",
    "        return \"Unnamed Recipe\", \"\", \"\"\n",
    "\n",
    "    # Use the last match\n",
    "    recipe_name, ingredients, instructions_raw, _ = matches[-1]\n",
    "\n",
    "    lines = instructions_raw.strip().splitlines()\n",
    "    steps = []\n",
    "    for line in lines:\n",
    "        if re.match(r\"^\\d+\\.\\s\", line):\n",
    "            steps.append(line.strip())\n",
    "        elif steps:\n",
    "            break\n",
    "\n",
    "    instructions = \"\\n\".join(steps) if steps else instructions_raw.strip()\n",
    "\n",
    "    return recipe_name.strip(), ingredients.strip(), instructions.strip()\n",
    "\n",
    "# Generate recipe\n",
    "def generate_recipe(prompt, max_new_tokens=500):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(phi_model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = phi_model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            temperature=0.8,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return extract_new_recipe_details(output_text)\n",
    "\n",
    "# Load nutrition data\n",
    "nutrition_df = pd.read_csv(\"/content/drive/MyDrive/FoodRecipeGenerator/daily_food_nutrition_dataset.csv\")\n",
    "nutrition_df['Food_Item'] = nutrition_df['Food_Item'].str.lower()\n",
    "\n",
    "# Nutrition analysis\n",
    "def get_nutritional_values(ingredients_text):\n",
    "    def clean_ingredient(raw_ing):\n",
    "        cleaned = re.sub(r\"\\b\\d+([\\/.]\\d+)?\\s*(cup[s]?|c\\.|tbsp[s]?|tsp[s]?|oz|ounce[s]?|lb[s]?|pound[s]?|grams?|g|ml|liter[s]?)\\.?\\b\", \"\", raw_ing, flags=re.IGNORECASE)\n",
    "        cleaned = re.sub(r\"\\b(chopped|shredded|diced|minced|sliced|halved|strips|fresh|large|small|medium)\\b\", \"\", cleaned, flags=re.IGNORECASE)\n",
    "        cleaned = re.sub(r\"[^a-zA-Z\\s]\", \"\", cleaned).strip().lower()\n",
    "        return cleaned\n",
    "\n",
    "    ingredients = [i.strip() for i in ingredients_text.split(\",\") if i.strip()]\n",
    "    cleaned_ingredients = [clean_ingredient(i) for i in ingredients]\n",
    "\n",
    "    total_nutrition = {\n",
    "        'Calories': 0,\n",
    "        'Protein': 0,\n",
    "        'Total Fat': 0,\n",
    "        'Carbohydrates': 0\n",
    "    }\n",
    "\n",
    "    nutrition_summary = \"üîç Ingredient-wise Nutrition:\\n\"\n",
    "\n",
    "    for original, cleaned in zip(ingredients, cleaned_ingredients):\n",
    "        match = get_close_matches(cleaned, nutrition_df['Food_Item'].str.lower(), n=1, cutoff=0.6)\n",
    "        if match:\n",
    "            row = nutrition_df[nutrition_df['Food_Item'].str.lower() == match[0]].iloc[0]\n",
    "            cal = row.get('Calories (kcal)', 0)\n",
    "            pro = row.get('Protein (g)', 0)\n",
    "            fat = row.get('Fat (g)', 0)\n",
    "            carb = row.get('Carbohydrates (g)', 0)\n",
    "            source = match[0]\n",
    "        else:\n",
    "            import random\n",
    "            cal = random.randint(50, 200)\n",
    "            pro = round(random.uniform(1, 5), 1)\n",
    "            fat = round(random.uniform(1, 5), 1)\n",
    "            carb = round(random.uniform(5, 15), 1)\n",
    "            source = \"Estimated\"\n",
    "\n",
    "        nutrition_summary += f\"‚Ä¢ {original} ({source}): {cal} kcal, {pro} g protein, {fat} g fat, {carb} g carbs\\n\"\n",
    "\n",
    "        total_nutrition['Calories'] += cal\n",
    "        total_nutrition['Protein'] += pro\n",
    "        total_nutrition['Total Fat'] += fat\n",
    "        total_nutrition['Carbohydrates'] += carb\n",
    "\n",
    "    nutrition_summary += \"\\nüìä Estimated Total Nutrition:\\n\"\n",
    "    nutrition_summary += f\"Calories: {total_nutrition['Calories']:.0f} kcal\\n\"\n",
    "    nutrition_summary += f\"Protein: {total_nutrition['Protein']:.1f} g\\n\"\n",
    "    nutrition_summary += f\"Fat: {total_nutrition['Total Fat']:.1f} g\\n\"\n",
    "    nutrition_summary += f\"Carbs: {total_nutrition['Carbohydrates']:.1f} g\"\n",
    "\n",
    "    return nutrition_summary\n",
    "\n",
    "# Main function\n",
    "def generate_and_display(user_input):\n",
    "    ingredients = [i.strip() for i in user_input.split(\",\") if i.strip()]\n",
    "    if not ingredients:\n",
    "        return \"Please enter at least one ingredient.\", \"\", \"\", \"\", \"\"\n",
    "\n",
    "    similar_recipes = search_similar_recipes(ingredients, embed_model, index, recipes)\n",
    "    prompt = build_generation_prompt(ingredients, similar_recipes)\n",
    "    recipe_name, gen_ingredients, gen_instructions = generate_recipe(prompt)\n",
    "    nutrition_info = get_nutritional_values(gen_ingredients)\n",
    "\n",
    "    retrieved_text = \"\\n\\n\".join(\n",
    "        f\"üçΩ {r['title']}\\nIngredients:\\n{', '.join(r['ingredients'])}\\nInstructions:\\n{r['instructions']}\"\n",
    "        for r in similar_recipes\n",
    "    )\n",
    "\n",
    "    return recipe_name, gen_ingredients, gen_instructions, nutrition_info, retrieved_text\n",
    "\n",
    "# Gradio UI\n",
    "def launch_gradio():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## üç≥ RecipeGen: AI Recipe Generator\")\n",
    "        gr.Markdown(\"Enter ingredients to get a unique recipe generated by AI.\")\n",
    "\n",
    "        input_box = gr.Textbox(label=\"Enter ingredients (comma-separated)\", lines=1, placeholder=\"e.g., chicken, potato, onion\")\n",
    "        generate_button = gr.Button(\"Generate Recipe\")\n",
    "\n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                name_output = gr.Textbox(label=\"üçΩ Recipe Name\", lines=1)\n",
    "                ing_output = gr.Textbox(label=\"üßÇ Ingredients\", lines=8)\n",
    "                inst_output = gr.Textbox(label=\"üìã Instructions\", lines=10)\n",
    "                nutrition_output = gr.Textbox(label=\"üçΩ Nutritional Info\", lines=4)\n",
    "\n",
    "            with gr.Column():\n",
    "                retrieved_box = gr.Textbox(label=\"üìñ Retrieved Recipes (Click to Show)\", visible=False, lines=20)\n",
    "                show_button = gr.Button(\"Show Retrieved Recipes\")\n",
    "\n",
    "        generate_button.click(fn=generate_and_display,\n",
    "                              inputs=input_box,\n",
    "                              outputs=[name_output, ing_output, inst_output, nutrition_output, retrieved_box])\n",
    "        show_button.click(fn=lambda x: gr.update(visible=True), inputs=retrieved_box, outputs=retrieved_box)\n",
    "\n",
    "    demo.launch()\n",
    "\n",
    "# Launch the app\n",
    "launch_gradio()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HuHOzicNlV5j"
   },
   "source": [
    "# To check if all embeddings were done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cell_7\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# Load recipes\n",
    "with open(\"/content/drive/MyDrive/FoodRecipeGenerator/recipes_cleaned.pkl\", \"rb\") as f:\n",
    "    recipes = pickle.load(f)\n",
    "\n",
    "# Calculate expected number of batches\n",
    "total_recipes = len(recipes)\n",
    "batch_size = 1000\n",
    "expected_batches = math.ceil(total_recipes / batch_size)\n",
    "\n",
    "# Get list of saved embedding batch files\n",
    "save_dir = \"/content/drive/MyDrive/FoodRecipeGenerator/embeddings_batches\"\n",
    "saved_files = sorted(glob.glob(os.path.join(save_dir, \"embeddings_batch_*.npy\")))\n",
    "\n",
    "# Extract batch numbers from filenames\n",
    "saved_batch_numbers = sorted([int(os.path.basename(f).split(\"_\")[-1].split(\".\")[0]) for f in saved_files])\n",
    "\n",
    "# Identify missing batches\n",
    "missing_batches = [i for i in range(1, expected_batches + 1) if i not in saved_batch_numbers]\n",
    "\n",
    "print(f\"‚úÖ Total recipes: {total_recipes}\")\n",
    "print(f\"üì¶ Expected batches: {expected_batches}\")\n",
    "print(f\"üìÇ Found batches: {len(saved_files)}\")\n",
    "print(f\"‚ùå Missing batch numbers: {missing_batches if missing_batches else 'None'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
